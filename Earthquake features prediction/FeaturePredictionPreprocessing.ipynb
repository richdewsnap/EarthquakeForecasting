{"cells":[{"cell_type":"code","source":["!pip install obspy"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PIX-d0Cua_yT","executionInfo":{"status":"ok","timestamp":1661317463080,"user_tz":-60,"elapsed":8473,"user":{"displayName":"RRocksmasher","userId":"16190049861015857899"}},"outputId":"aa96c005-de1a-4e94-8487-094bb6f1abe7"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: obspy in /usr/local/lib/python3.7/dist-packages (1.3.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from obspy) (2.23.0)\n","Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from obspy) (1.7.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from obspy) (57.4.0)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from obspy) (4.9.1)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from obspy) (1.21.6)\n","Requirement already satisfied: matplotlib>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from obspy) (3.2.2)\n","Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.7/dist-packages (from obspy) (1.4.40)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from obspy) (4.4.2)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.0->obspy) (2.8.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.0->obspy) (0.11.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.0->obspy) (1.4.4)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.0->obspy) (3.0.9)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib>=3.2.0->obspy) (4.1.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=3.2.0->obspy) (1.15.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->obspy) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->obspy) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->obspy) (2022.6.15)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->obspy) (3.0.4)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy->obspy) (4.12.0)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy->obspy) (1.1.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy->obspy) (3.8.1)\n"]}]},{"cell_type":"markdown","metadata":{"id":"Nych_HGDInp0"},"source":["# read, format and classify data from original mseed files\n","\n","Ong, Giani, Nielsen\n","\n","Modified for multiple stations by Dewsnap"]},{"cell_type":"markdown","source":["**mount Google Drive as a disk to access files and data**\n","\n"],"metadata":{"id":"Hh0Cs2E1dI_k"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QC1Khy8bItpr","executionInfo":{"status":"ok","timestamp":1661317464459,"user_tz":-60,"elapsed":1396,"user":{"displayName":"RRocksmasher","userId":"16190049861015857899"}},"outputId":"1ce5af01-d320-4ad5-f918-85e72b2c2631"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["cd \"/content/drive/MyDrive/DISS_FOLDER/New_Data\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"41kFW86rIu6T","executionInfo":{"status":"ok","timestamp":1661317464460,"user_tz":-60,"elapsed":7,"user":{"displayName":"RRocksmasher","userId":"16190049861015857899"}},"outputId":"25adaf3a-f7bd-412e-e272-759ef8073a03"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/DISS_FOLDER/New_Data\n"]}]},{"cell_type":"markdown","source":["### **INITIALISATION**"],"metadata":{"id":"Z4VjuQkK-R2P"}},{"cell_type":"code","source":["choice = 'new2' # old=norm on all 3 components together. new2=no norm. new=norm on individual components,\n","\n","\n","years = [2014,2015,2016,2017,2018,2019,2020,2021,2022] #add more when more folders are finished\n","#2013 has no events with full data\n","#INCN is offline for most of 2012-2013 (alongside other stations missing entries/axes)\n","#2012 all entries have anomalies.\n","numStations = 3\n","\n","stationNames = [\"MAJO.IU\",\"ERM.II\",\"INCN.IU\"]\n","\n","for i in range(numStations):\n","  print(\"Taking events from station \"+stationNames[i])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_LBq4MNZ-SDb","executionInfo":{"status":"ok","timestamp":1661317464892,"user_tz":-60,"elapsed":436,"user":{"displayName":"RRocksmasher","userId":"16190049861015857899"}},"outputId":"763d1bc6-de48-42c0-80c9-ffe8866bfe56"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Taking events from station MAJO.IU\n","Taking events from station ERM.II\n","Taking events from station INCN.IU\n"]}]},{"cell_type":"code","source":["\n","\n","def getOutputs():\n","\n","  dataString = \"\"\"#myId|#EventID | Time | Latitude | Longitude | Depth/km | Author | Catalog | Contributor | ContributorID | MagType | Magnitude | MagAuthor | EventLocationName\n","  #myId|#EventID | Time | Latitude | Longitude | Depth/km | Author | Catalog | Contributor | ContributorID | MagType | Magnitude | MagAuthor | EventLocationName\n","  #myId|#EventID | Time | Latitude | Longitude | Depth/km | Author | Catalog | Contributor | ContributorID | MagType | Magnitude | MagAuthor | EventLocationName\n","  E7|11512781|2022-01-03T09:46:35|23.9938|122.2595|19.0|us,usauto,pt|NEIC PDE|us|us7000g8n3,pt22003001,usauto7000g8n3|mww|6.2|us|TAIWAN REGION\n","  E6|11519353|2022-01-21T16:08:37|32.7437|132.0432|39.0|at,us,usauto,pt|NEIC PDE|us|us7000gdwz,pt22021000,at00r62i6f,usauto7000gdwz|Mww|6.3|us|SHIKOKU, JAPAN\n","  E5|11540112|2022-03-16T14:34:27|37.6468|141.6735|57.18|us,usauto,pt,at|NEIC PDE|us|usauto6000h518,us6000h518,pt22075003,at00r8udte|mwb|6.0|us|NEAR EAST COAST OF HONSHU, JAPAN\n","  E11|11414199|2021-05-13T23:58:14|37.7079|141.7784|32.0|us,usauto,pt,at|NEIC PDE|us|usauto7000e2xd,us7000e2xd,pt21134000,at00qt2l91|mww|6.0|us|NEAR EAST COAST OF HONSHU, JAPAN\n","  E4|11496103|2021-11-10T15:45:13|23.5934|126.4478|12.0|us,pt,usauto,at|NEIC PDE|us|us7000fszl,usauto7000fszl,pt21314000,at00r2d53g|Mww|6.6|us|SOUTHEAST OF RYUKYU ISLANDS\n","  E1|11505493|2021-12-09T02:05:07|29.4132|129.3846|7.0|us,usauto,pt,at|NEIC PDE|us|at00r3tsgo,usauto6000gaq5,pt21343000,us6000gaq5|Mww|6.0|us|RYUKYU ISLANDS, JAPAN\n","  E2|11350948|2020-12-10T13:19:58|24.7632|122.0098|73.17|us,usauto,pt,at|NEIC PDE|us|us7000cpqz,pt20345000,usauto7000cpqz,at00ql4l1c|mww|6.1|us|TAIWAN REGION\n","  E10|10993586|2019-01-08T12:39:31|30.5926|131.0371|35.0|us|NEIC PDE|us|us2000j1d4|Mww|6.3|us|KYUSHU, JAPAN\n","  E8|11024574|2019-04-11T08:18:21|40.4096|143.2985|18.0|us|NEIC PDE|us|us700034d3|Mww|6.0|us|OFF EAST COAST OF HONSHU, JAPAN\n","  E1|11091618|2019-08-04T10:23:03|37.7597|141.6089|38.0|us|NEIC PDE|us|us600050if|Mww|6.3|us|NEAR EAST COAST OF HONSHU, JAPAN\n","  E7|10639985|2018-02-06T15:50:43|24.1359|121.658|17.0|us|NEIC PDE|us|us1000chhc|Mww|6.4|us|TAIWAN\n","  E9|10608258|2018-01-24T10:51:19|41.1034|142.4323|31.0|us|NEIC PDE|us|us2000cnnl|Mww|6.3|us|HOKKAIDO, JAPAN REGION\n","  E6|10902101|2018-07-06T01:40:04|51.4994|157.8404|45.0|us|NEIC PDE|us|us2000fxyz|Mww|6.1|us|NEAR EAST COAST OF KAMCHATKA\n","  E3|10957286|2018-10-09T07:45:11|49.3941|156.2319|20.0|us|NEIC PDE|us|us1000h97j|Mww|6.1|us|KURIL ISLANDS\n","  E5|10936428|2018-08-16T18:22:53|23.4226|143.3187|20.0|us|NEIC PDE|us|us1000gaqv|Mww|6.3|us|VOLCANO ISLANDS, JAPAN REGION\n","  E4|10944513|2018-09-05T18:07:59|42.6861|141.9294|35.0|us,pt,at|NEIC PDE|us|pt18248000,at00pelgzo,us2000h8ty|Mww|6.6|us|HOKKAIDO, JAPAN REGION\n","  E3|10406737|2017-09-20T16:37:16|37.9814|144.6601|11.0|us|NEIC PDE|us|us2000arxv|Mww|6.1|us|OFF EAST COAST OF HONSHU, JAPAN\n","  E4|10401792|2017-09-07T17:26:49|27.7829|139.8041|451.0|us|NEIC PDE|us|us2000ahlq|Mww|6.1|us|BONIN ISLANDS, JAPAN REGION\n","  E2|10411586|2017-10-06T07:59:32|37.5033|144.0201|9.0|us|NEIC PDE|us|us2000b1v8|Mww|6.2|us|OFF EAST COAST OF HONSHU, JAPAN\n","  E1|10453666|2017-11-09T07:42:11|32.5208|141.438|12.0|us|NEIC PDE|us|us2000bkrv|Mww|6.0|us|SOUTHEAST OF HONSHU, JAPAN\n","  E9|5184131|2016-05-31T05:23:47|25.5615|122.5458|246.4|us,gcmt|NEIC PDE|us|gcmt20160531052347,us20005zay|mww|6.4|us|TAIWAN REGION\n","  E8|5189735|2016-08-04T16:24:33|24.9447|142.0141|510.0|us,gcmt|NEIC PDE||gcmt20160804162434,us10006a2k|mww|6.3|us,gcmt|VOLCANO ISLANDS, JAPAN REGION\n","  E3|5196026|2016-10-21T05:07:23|35.3676|133.8148|5.7|us,at,pt,gcmt|NEIC PDE|us|at00ofdswb,us20007fta,gcmt20161021050723,pt16295050|Mww|6.2|us|WESTERN HONSHU, JAPAN\n","  E2|5197585|2016-11-11T21:42:59|38.4973|141.5658|42.4|us|NEIC PDE|us|us1000770m|mww|6.1||NEAR EAST COAST OF HONSHU, JAPAN\n","  E15|10625663|2015-02-16T23:06:28|39.9468|143.1771|10.8|ISC|ISC|ISC|608402324|MW|6.7|GCMT|OFF EAST COAST OF HONSHU, JAPAN\n","  E14|5006299|2015-02-20T04:25:23|39.8189|143.6157|13.3|ISC|ISC|ISC|610586348|MW|6.2|GCMT|OFF EAST COAST OF HONSHU, JAPAN\n","  E10|5113626|2015-05-12T21:12:58|38.9005|142.0217|39.3|ISC|ISC|ISC|610588291|MW|6.8|GCMT|NEAR EAST COAST OF HONSHU, JAPAN\n","  E13|5006407|2015-02-21T10:13:53|39.8287|143.5175|12.2|ISC|ISC|ISC|610586373|MW|6.0|GCMT|OFF EAST COAST OF HONSHU, JAPAN\n","  E5|5150490|2015-07-07T05:10:27|43.9697|148.0042|51.1|ISC|ISC|ISC|611836168|MW|6.3|GCMT|EAST OF KURIL ISLANDS\n","  E7|10778316|2015-06-08T06:01:10|41.5071|142.0564|60.7|ISC|ISC|ISC|608295904|MW|6.1|GCMT|HOKKAIDO, JAPAN REGION\n","  E2|5161913|2015-10-14T05:43:08|48.8595|156.2259|12.0|us|NEIC PDE|us|us10003nib|mww|6.0|us|EAST OF KURIL ISLANDS\n","  E14|4479338|2014-03-13T17:06:51|33.6222|131.8077|83.4|ISC|ISC|ISC|604156129|MW|6.3|GCMT|KYUSHU, JAPAN\n","  E7|10360772|2014-08-10T03:43:19|41.2001|142.2065|55.6|IDC|ISC|ISC|610785780|MW|6.1|GCMT|HOKKAIDO, JAPAN REGION\n","  E15|4374929|2014-03-02T20:11:22|27.4238|127.3279|118.9|ISC|ISC|ISC|604087249|MW|6.5|GCMT|RYUKYU ISLANDS, JAPAN\n","  E6|4766096|2014-08-10T03:43:18|41.134|142.279|50.6|NIED|ISC|ISC|610785778|Mwc|6.1|GCMT|HOKKAIDO, JAPAN REGION\n","  E4|10530532|2014-11-09T14:38:15|46.93|140.63|10.0|SKHL|ISC|ISC|608910839|mb|7.6|SKHL|PRIMOR'YE, RUSSIA\"\"\"\n","\n","  tempDataList = dataString.split(\"\\n\")[3:]\n","\n","  dataList=[]\n","  for entry in tempDataList:\n","\n","    temp = entry.split(\"|\")\n","    temp2 = [temp[0].strip(),temp[2].split(\"-\")[0], temp[3:6],temp[11]]  #[Name, year, lat, long, depth, mag]\n","\n","    dataList.append(temp2)\n","    #print(temp2)\n","\n","  return dataList\n","\n","\n","dataList = getOutputs()\n","\n","dataList.reverse()   #so it's in the correct order as the loaded data\n","\n","print(len(dataList))\n","dataValuesList=[]\n","for entry in dataList:\n","  #print(entry)\n","\n","  temp = entry[2]\n","\n","  temp.append(entry[3])\n","\n","  temp = [float(k) for k in temp]\n","\n","  dataValuesList.append(temp)\n","\n","  print(dataValuesList[-1])\n","\n","\n","\n","\n","#Standardising the data:\n","\n","from math import sqrt\n","\n","N=len(dataValuesList)\n","Means=[0,0,0,0]\n","SDs=[0,0,0,0]\n","for event in dataValuesList:\n","\n","  for i in range(4):\n","    Means[i]+=event[i]/N #mean\n","    SDs[i]+=(event[i]**2)/N #mean of the squares\n","\n","for i in range(4):\n","  SDs[i] -= Means[i]**2 #- square of the means for the variance\n","  SDs[i] = sqrt(SDs[i]) #but rooted for the standard deviation\n","\n","for n in range(N):\n","  event = dataValuesList[n]\n","\n","  for i in range(4):\n","    event[i] = (event[i]-Means[i])/SDs[i]\n","\n","  dataValuesList[n]=event\n","\n","\n","\n","print(Means)\n","print(SDs)\n","\n","\n","# Means\n","#[35.9490611111111, 139.10234444444444, 63.99305555555556, 6.269444444444443]\n","#Variances\n","#[7.840629450223421, 9.138413709915895, 109.82974950701968, 0.30442974417067376]\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WwL2JPUd_P-X","executionInfo":{"status":"ok","timestamp":1661317464892,"user_tz":-60,"elapsed":6,"user":{"displayName":"RRocksmasher","userId":"16190049861015857899"}},"outputId":"25b8d786-8c8e-4168-845e-762a6edfc116"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["36\n","[46.93, 140.63, 10.0, 7.6]\n","[41.134, 142.279, 50.6, 6.1]\n","[27.4238, 127.3279, 118.9, 6.5]\n","[41.2001, 142.2065, 55.6, 6.1]\n","[33.6222, 131.8077, 83.4, 6.3]\n","[48.8595, 156.2259, 12.0, 6.0]\n","[41.5071, 142.0564, 60.7, 6.1]\n","[43.9697, 148.0042, 51.1, 6.3]\n","[39.8287, 143.5175, 12.2, 6.0]\n","[38.9005, 142.0217, 39.3, 6.8]\n","[39.8189, 143.6157, 13.3, 6.2]\n","[39.9468, 143.1771, 10.8, 6.7]\n","[38.4973, 141.5658, 42.4, 6.1]\n","[35.3676, 133.8148, 5.7, 6.2]\n","[24.9447, 142.0141, 510.0, 6.3]\n","[25.5615, 122.5458, 246.4, 6.4]\n","[32.5208, 141.438, 12.0, 6.0]\n","[37.5033, 144.0201, 9.0, 6.2]\n","[27.7829, 139.8041, 451.0, 6.1]\n","[37.9814, 144.6601, 11.0, 6.1]\n","[42.6861, 141.9294, 35.0, 6.6]\n","[23.4226, 143.3187, 20.0, 6.3]\n","[49.3941, 156.2319, 20.0, 6.1]\n","[51.4994, 157.8404, 45.0, 6.1]\n","[41.1034, 142.4323, 31.0, 6.3]\n","[24.1359, 121.658, 17.0, 6.4]\n","[37.7597, 141.6089, 38.0, 6.3]\n","[40.4096, 143.2985, 18.0, 6.0]\n","[30.5926, 131.0371, 35.0, 6.3]\n","[24.7632, 122.0098, 73.17, 6.1]\n","[29.4132, 129.3846, 7.0, 6.0]\n","[23.5934, 126.4478, 12.0, 6.6]\n","[37.7079, 141.7784, 32.0, 6.0]\n","[37.6468, 141.6735, 57.18, 6.0]\n","[32.7437, 132.0432, 39.0, 6.3]\n","[23.9938, 122.2595, 19.0, 6.2]\n","[35.94906111111111, 139.1023444444444, 63.993055555555564, 6.269444444444444]\n","[7.840629450223392, 9.13841370991669, 109.8297495070197, 0.3044297441706504]\n"]}]},{"cell_type":"markdown","source":["**load libraries for importing and formatting the input data:**\n","---\n","\n"],"metadata":{"id":"sqH9fQ__dRbD"}},{"cell_type":"code","execution_count":6,"metadata":{"id":"TqvHc6CzInp3","executionInfo":{"status":"ok","timestamp":1661317465632,"user_tz":-60,"elapsed":745,"user":{"displayName":"RRocksmasher","userId":"16190049861015857899"}}},"outputs":[],"source":["from obspy import read as readobs\n","from obspy import read_inventory\n","from matplotlib import pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import pickle\n","import os\n","import random\n","import math"]},{"cell_type":"markdown","source":["**Import the \"original\" data from mseed files, format them:**"],"metadata":{"id":"2y5KYHQ2dxue"}},{"cell_type":"code","execution_count":7,"metadata":{"id":"oD_ufQuRInp5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661317485344,"user_tz":-60,"elapsed":19715,"user":{"displayName":"RRocksmasher","userId":"16190049861015857899"}},"outputId":"c1afe454-e11c-4a1b-cfdd-7c83699d4a68"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","=============\n","2014\n","5 events\n","=============\n","\n","2014_E4.996941\n","2014_E6.125507\n","2014_E15.958592\n","2014_E7.767260\n","2014_E14.417538\n","\n","=============\n","2015\n","6 events\n","=============\n","\n","2015_E2.41843\n","2015_E7.512251\n","2015_E5.34634\n","2015_E10.502950\n","2015_E14.799543\n","2015_E15.257925\n","\n","=============\n","2016\n","4 events\n","=============\n","\n","2016_E2.15144\n","2016_E3.823861\n","2016_E8.149332\n","2016_E9.871807\n","\n","=============\n","2017\n","4 events\n","=============\n","\n","2017_E1.727519\n","2017_E2.174189\n","2017_E4.721584\n","2017_E3.654490\n","\n","=============\n","2018\n","6 events\n","=============\n","\n","2018_E4.590218\n","2018_E5.447225\n","2018_E3.920499\n","2018_E6.658486\n","2018_E9.425817\n","2018_E7.37024\n","\n","=============\n","2019\n","3 events\n","=============\n","\n","2019_E1.463352\n","2019_E8.941687\n","2019_E10.518755\n","\n","=============\n","2020\n","1 events\n","=============\n","\n","2020_E2.774661\n","\n","=============\n","2021\n","3 events\n","=============\n","\n","2021_E1\n","2021_E4\n","2021_E11\n","\n","=============\n","2022\n","3 events\n","=============\n","\n","2022_E5\n","2022_E6\n","2022_E7\n","35\n","1153317\n","Flagged!\n","Errors on 20\n","Errors on 0\n","\n","34\n"]}],"source":["# Read all datafiles in folder and store them in \"events\":\n","\n","events = []\n","K=0\n","for year in years:\n","    print(\"\\n=============\")\n","    print(year)\n","    yearPath = './'+str(year)\n","\n","    eventNames = os.listdir(yearPath)\n","    print(str(len(eventNames))+\" events\")\n","    print(\"=============\\n\")\n","\n","    K = K+len(eventNames)\n","    for event in eventNames:\n","      #i+=1\n","      #print(\"Event\" + str(i))\n","      print(event)\n","\n","      #for i in range(numStations):\n","      events.append([readobs(\"./\"+str(year)+\"/\"+event+\"/\"+station+\".mseed\") for station in stationNames])\n","      #events.append(read(\"./Data/seeddata32/TEST8.mseed\"))\n","\n","print(K)\n","\n","\n","# Form selectedevents, extract the 3 channels as data, and store them in \"eventdata\"\n","eventdata = []\n","for I in range(len(events)):\n","    event = events[I] #for each event's data\n","    stationData = []\n","    for station in event: # for each station\n","      flag = False\n","      for i in range(3): #for each axis (x,y,z), deals with multiple stations e.g for 2 stations gives a list of the form [x1,y1,z1,x2,y2,z2]\n","        stationData.append(station[i].data)\n","        #print(len(station[i].data))\n","        if len(station[i].data)!=1440000:\n","          print(len(station[i].data))\n","          flag=True\n","          print(\"Flagged!\")\n","          print(\"Errors on \"+str(I))\n","          #print(\"Errors on \"+station)\n","          print(\"Errors on \"+str(i))\n","          print(\"\")\n","          K-=1\n","          break\n","    if flag ==False:\n","      eventdata.append(stationData)\n","print(K)\n","    \n","#Concatenate channels for each event\n","eventdataconcat = []\n","for stationAxis in eventdata:\n","    data_concat_TEMP=0\n","    for i in range(3*numStations):\n","      st_TEMP = np.expand_dims(stationAxis[i],axis=-1)\n","\n","      if isinstance(data_concat_TEMP,int):\n","        data_concat_TEMP=st_TEMP\n","      else:\n","        data_concat_TEMP = np.c_[data_concat_TEMP,st_TEMP]\n","\n","    #sta = np.expand_dims(event[0], axis=-1)\n","    #stb = np.expand_dims(event[1], axis=-1)\n","    #stc = np.expand_dims(event[2], axis=-1)\n","    eventdataconcat.append(data_concat_TEMP)\n","\n","#print(eventdataconcat[0][0])\n"]},{"cell_type":"markdown","metadata":{"id":"ulbYcvOyInp8"},"source":["The structure of each event in \"eventdataconcat\" is (for 2 stations): <br>\n","array([  <br>\n","[x1, y1, z1, x2, y2, z2], # time 1 <br>\n","[x1, y1, z1, x2, y2, z2], # time 2 <br>\n","..... <br>\n","[x1, y1, z1, x2, y2, z2]  # time n <br>\n","]) <br>\n","(n is the total number of time samples)"]},{"cell_type":"markdown","metadata":{"id":"Cv2PZkgXInp-"},"source":["### Extract first and last 40k samples and class as noise and precusros, respectivley"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"DYqNoY7zInp_","executionInfo":{"status":"ok","timestamp":1661317485345,"user_tz":-60,"elapsed":19,"user":{"displayName":"RRocksmasher","userId":"16190049861015857899"}}},"outputs":[],"source":["def create_precursors(X1, last = 40000):\n","    precurstr = X1[-last:] \n","    return(precurstr)\n","    \n","#def create_noise(X1, first = 0, second = 40000):\n","#    precurstr = X1[first:second]\n","       \n","#    return(precurstr)\n","\n","#Select the final 40000 time steps from each event (all 3 channels) and label as 'precursors' \n","#Select the first 40000 time steps from each event (all 3 channels) and label as 'noise' \n","\n","precursors = []\n","#noise = []\n","for event in eventdataconcat:\n","    precursors.append(create_precursors(event,40000))\n","    \n","#for event in eventdataconcat:\n","#    noise.append(create_noise(event, 0, 40000))"]},{"cell_type":"markdown","metadata":{"id":"tZ_RNWEfInqB"},"source":["### Make windows of length \"window_length\" from the selected 'noise' and 'precursor' data \n","The windows overlap of 650 timesteps\n","With this overlap, each precursor window of 40000 samples produces 37 \"normpre\"v windows of 16384 samples. \n","Same for noise windows."]},{"cell_type":"code","execution_count":9,"metadata":{"id":"SGcZqwSIInqC","executionInfo":{"status":"ok","timestamp":1661317485345,"user_tz":-60,"elapsed":18,"user":{"displayName":"RRocksmasher","userId":"16190049861015857899"}}},"outputs":[],"source":["window_length=16384\n","\n","def make_windows(X1, sample_stride = 650):\n","    X2 = []\n","    for i in range(len(X1)-window_length):        \n","        if i % sample_stride == 0:\n","               X2.append(X1[i:i+window_length])    \n","    return(X2)\n","   \n","precursor_windows = []\n","for event in precursors:\n","    precursor_windows.append(make_windows(event, 650))\n","    \n","#noise_windows = []\n","#for event in noise:\n","#    noise_windows.append(make_windows(event, 650))"]},{"cell_type":"markdown","metadata":{"id":"GztF4tDfInqD"},"source":["### Normalisation of signal\n","Three different options for normalisation fuction: \n","- new \n","- new2\n","- old\n","\n","In previous work (Ong et al.) normalisation_old was used. "]},{"cell_type":"code","execution_count":10,"metadata":{"id":"XUA3bWGLInqE","executionInfo":{"status":"ok","timestamp":1661317485623,"user_tz":-60,"elapsed":295,"user":{"displayName":"RRocksmasher","userId":"16190049861015857899"}}},"outputs":[],"source":["def normalise_new(X1): # Here each 3 individual component of each window is mean stripped and normalised\n","    X2 = []\n","    for data in X1:\n","        values = np.zeros((len(data),3))\n","        mea=np.mean(data,axis=0).reshape(-1, 1)\n","        values = (data.T-mea).T\n","        values = values / np.linalg.norm(values,axis=0,ord=np.Inf) # L_infinity norm???????????\n","        X2.append(values)\n","    return X2\n","\n","def normalise_new2(X1): # not normalise, not strip mean\n","    X2 = []\n","    for data in X1:\n","        values = np.zeros((len(data),3))\n","        values = data\n","        X2.append(values)\n","    return X2\n","\n","def normalise_old(X1): ## Here the 3 components are mean stripped and normalised together, results strange but working for the CNN:\n","    X2 = []\n","    for data in X1:\n","        values = np.zeros((len(data),3))\n","        values = data - np.mean(data)\n","        values = values / np.linalg.norm(values)\n","        X2.append(values)\n","    return X2\n","\n","\n","normpre = []\n","normnoise = []\n","\n","if choice == 'new2':\n","  for event in precursor_windows:    normpre.append(normalise_new2(event))\n","  #for event in noise_windows:    normnoise.append(normalise_new2(event))\n","elif choice == 'old':\n","  for event in precursor_windows:    normpre.append(normalise_old(event))\n","  #for event in noise_windows:    normnoise.append(normalise_old(event))\n","elif choice == 'new':\n","  for event in precursor_windows:    normpre.append(normalise_new(event))\n","  #for event in noise_windows:    normnoise.append(normalise_new(event))\n"]},{"cell_type":"markdown","metadata":{"id":"NkZxW7SgInqG"},"source":["### Select events for train and test datasets. These events were randomly selected."]},{"cell_type":"code","execution_count":11,"metadata":{"id":"fDrXfYaFInqG","executionInfo":{"status":"ok","timestamp":1661317485624,"user_tz":-60,"elapsed":8,"user":{"displayName":"RRocksmasher","userId":"16190049861015857899"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"d57ff72a-d60b-48f7-e500-ef3192facd49"},"outputs":[{"output_type":"stream","name":"stdout","text":["[1, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32]\n","27\n","\n","[0, 2, 8, 12, 15, 19, 33]\n","7\n"]}],"source":["trainlist = []\n","\n","trainlist = [1, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32]\n","testlist = [0, 2, 8, 12, 15, 19, 33]\n","\n","if len(trainlist)==0:\n","\n","  K=len(eventdataconcat)\n","\n","  print(K)\n","\n","  trainlist = random.sample(range(K),round(4*K/5))\n","\n","  temp = set(trainlist)\n","  temp2 = set(range(K))\n","\n","  testlist = list(temp2-temp)\n","\n","print(sorted(trainlist))\n","print(len(trainlist))\n","print()\n","print(sorted(testlist))\n","print(len(testlist))\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"-XOyQ4YbInqH"},"source":["## output data to files for further use by the CNN"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"NqXIFoPCInqH","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f652294f-85b9-43ca-c073-be82b549e53f","executionInfo":{"status":"ok","timestamp":1661317489536,"user_tz":-60,"elapsed":3918,"user":{"displayName":"RRocksmasher","userId":"16190049861015857899"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["new2\n"]}],"source":["print(choice)\n","pickle.dump( normpre, open( \"./Feature_Data/normpre_\"+choice+\".p\", \"wb\" ) ) # pickle file with all precursor windows\n","pickle.dump( dataValuesList, open( \"./Feature_Data/normnoise_\"+choice+\".p\", \"wb\" ) ) # pickle file with all noise windows\n","pickle.dump( trainlist, open( \"./Feature_Data/trainlist.p\", \"wb\" ) ) # pickel file with the labels of events in train data\n","pickle.dump( testlist, open( \"./Feature_Data/testlist.p\", \"wb\" ) ) # pickle file with labels of events in test data\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.8"},"colab":{"name":"FeaturePredictionPreprocessing.ipynb","provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":0}